{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Support Vector Machines (SVM) Tutorial\n",
        "\n",
        "This notebook accompanies the SVM tutorial PDF. It demonstrates SVM using the Iris dataset, compares kernels (linear, polynomial, RBF), shows decision boundaries (using two features), performs hyperparameter search, and evaluates results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Iris dataset and prepare a binary classification problem: Setosa vs Versicolor\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, [0, 2]]  # use sepal length (0) and petal length (2) for easy visualization\n",
        "y = iris.target\n",
        "\n",
        "# Select two classes: class 0 (setosa) and class 1 (versicolor)\n",
        "mask = (y == 0) | (y == 1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "print('Dataset shape:', X.shape)\n",
        "print('Class distribution:', np.bincount(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper to plot decision boundaries for 2D data\n",
        "def plot_decision_boundaries(clf, X, y, title='Decision boundary'):\n",
        "    # create grid\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300), np.linspace(y_min, y_max, 300))\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "    Z = clf.predict(grid)\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.2)\n",
        "    plt.scatter(X[:,0], X[:,1], c=y, edgecolor='k')\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.title(title)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train SVMs with different kernels and show results\n",
        "kernels = ['linear', 'poly', 'rbf']\n",
        "models = {}\n",
        "for k in kernels:\n",
        "    if k == 'poly':\n",
        "        clf = svm.SVC(kernel=k, degree=3, C=1.0, probability=True)\n",
        "    else:\n",
        "        clf = svm.SVC(kernel=k, C=1.0, probability=True)\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "    models[k] = clf\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Kernel={k:6s}  Test accuracy={acc:.4f}\")\n",
        "    plot_decision_boundaries(clf, np.vstack([X_train_scaled, X_test_scaled]), np.hstack([y_train, y_test]), title=f'SVM ({k})')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid search for RBF kernel hyperparameters (C and gamma)\n",
        "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1], 'kernel': ['rbf']}\n",
        "grid = GridSearchCV(svm.SVC(), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "print('Best params (RBF):', grid.best_params_)\n",
        "best_rbf = grid.best_estimator_\n",
        "y_pred = best_rbf.predict(X_test_scaled)\n",
        "print('Test acc (best RBF):', accuracy_score(y_test, y_pred))\n",
        "plot_decision_boundaries(best_rbf, np.vstack([X_train_scaled, X_test_scaled]), np.hstack([y_train, y_test]), title='Best RBF (GridSearch)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix and classification report for best model\n",
        "print('Confusion matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model and scaler\n",
        "joblib.dump(best_rbf, 'svm_rbf_best.joblib')\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "print('Saved model: svm_rbf_best.joblib and scaler.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- The notebook uses only two features so decision boundaries can be visualized.\n",
        "- For real work, consider using all features and cross-validation pipelines.\n",
        "- Remember to cite sources in your report (e.g., Cortes & Vapnik 1995, scikit-learn docs).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}